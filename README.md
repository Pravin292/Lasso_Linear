# ðŸ“‰ Lasso & Ridge Linear Optimization

A deep dive into L1 and L2 regularization techniques. This project implements a comparative analysis of Lasso and Ridge regression to improve model stability, control overfitting, and perform automated feature selection.

---

## ðŸš€ Key Features
- ðŸ”¹ **Regularization Comparison**: Side-by-side analysis of L1 (Lasso) vs. L2 (Ridge) penalty effects.
- ðŸ”¹ **Feature Selection Intelligence**: Demonstrates Lasso's capability to shrink coefficients to zero for automated variable selection.
- ðŸ”¹ **Hyperparameter Tuning**: Cross-validation loops for finding the optimal alpha (lambda) values.
- ðŸ”¹ **Stability Metrics**: Evaluation of model performance on high-variance datasets.

## ðŸ“Š Technical Stack
- **Models**: Lasso, Ridge, and ElasticNet Regression
- **Framework**: Scikit-Learn
- **Validation**: K-Fold Cross Validation
- **Visualization**: Coefficient Path Plots

---
Â© 2026 Pravin | Data Science Portfolio
